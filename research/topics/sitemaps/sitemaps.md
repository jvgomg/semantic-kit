---
title: "XML Sitemaps"
lastVerified: 2026-02-04
lastUpdated: 2026-02-04
---

# XML Sitemaps

XML sitemaps are structured files that inform search engines and crawlers about URLs available for crawling on a website, including metadata about when pages were last updated.

## Overview

The Sitemap protocol was developed in 2005 by Google and later adopted by Microsoft, Yahoo, and others in 2006. The specification is maintained at [sitemaps.org](https://www.sitemaps.org/) [^sitemaps-org].

Sitemaps serve two primary purposes:

1. **URL Discovery** - Help crawlers find pages that might be difficult to discover through regular link-following (orphan pages, deep navigation, dynamically generated content)
2. **Crawl Prioritization** - Signal which pages have been recently updated via `<lastmod>` timestamps

## Protocol Specification

### Supported Formats

Search engines accept three sitemap formats [^google-build-sitemap]:

| Format | Use Case | Features |
|--------|----------|----------|
| XML | Most versatile | Extensions for images, video, news, hreflang |
| RSS/Atom | Sites with existing feeds | Auto-generated by most CMSes |
| Text | Simple URL lists | One URL per line, no metadata |

### XML Structure

A minimal valid sitemap requires three elements [^sitemaps-protocol]:

```xml
<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
  <url>
    <loc>https://example.com/page</loc>
  </url>
</urlset>
```

**Required elements:**
- `<urlset>` - Root element with namespace declaration
- `<url>` - Container for each URL entry
- `<loc>` - Absolute URL (max 2,048 characters)

**Optional elements:**

| Element | Description | Notes |
|---------|-------------|-------|
| `<lastmod>` | Last modification date | W3C Datetime format (YYYY-MM-DD) |
| `<changefreq>` | Expected change frequency | **Ignored by Google** |
| `<priority>` | Relative importance (0.0-1.0) | **Ignored by Google** |

Google explicitly states it ignores `<changefreq>` and `<priority>` values, using only `<lastmod>` if it's "consistently and verifiably accurate" [^google-build-sitemap].

### Character Encoding

Sitemaps must be UTF-8 encoded. Special characters require XML entity escaping:

| Character | Entity |
|-----------|--------|
| `&` | `&amp;` |
| `'` | `&apos;` |
| `"` | `&quot;` |
| `<` | `&lt;` |
| `>` | `&gt;` |

URLs must comply with RFC-3986 (URIs) and RFC-3987 (IRIs) [^sitemaps-protocol].

### Size Limits

| Limit | Value |
|-------|-------|
| Maximum URLs per sitemap | 50,000 |
| Maximum file size (uncompressed) | 50 MB |
| Maximum sitemaps per index | 50,000 |
| Theoretical maximum URLs | 2.5 billion |

For sites exceeding these limits, use a **sitemap index file**.

## Sitemap Index Files

Large sites can organize multiple sitemaps using an index file [^google-large-sitemaps]:

```xml
<?xml version="1.0" encoding="UTF-8"?>
<sitemapindex xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
  <sitemap>
    <loc>https://example.com/sitemap-products.xml</loc>
    <lastmod>2026-02-04</lastmod>
  </sitemap>
  <sitemap>
    <loc>https://example.com/sitemap-blog.xml</loc>
    <lastmod>2026-02-03</lastmod>
  </sitemap>
</sitemapindex>
```

**Directory rules:** Referenced sitemaps must be in the same directory as the index file or deeper in the hierarchy. A sitemap index at `/public/sitemap-index.xml` can only reference sitemaps under `/public/`.

**Organization strategies:**
- By content type (products, blog posts, categories)
- By update frequency (frequently changing vs. static)
- By date (monthly archives)

## Sitemap Discovery

Search engines discover sitemaps through multiple mechanisms:

### 1. robots.txt (Recommended)

Add a `Sitemap:` directive anywhere in your robots.txt file [^robots-txt-sitemap]:

```
User-agent: *
Allow: /

Sitemap: https://example.com/sitemap.xml
Sitemap: https://example.com/sitemap-news.xml
```

The `Sitemap:` directive is case-insensitive and can appear multiple times. It's independent of any `User-agent` blocks.

### 2. HTML `<link>` Element

Add a link element in the document `<head>` [^astro-sitemap]:

```html
<link rel="sitemap" href="/sitemap.xml" />
```

This method is less universally supported than robots.txt but can be useful for single-page applications or sites without robots.txt access.

### 3. Search Console Submission

Direct submission via Google Search Console or Bing Webmaster Tools provides:
- Immediate notification to search engines
- Detailed error reporting and diagnostics
- Indexing statistics per sitemap

### 4. HTTP Ping (Deprecated)

Historically, search engines accepted HTTP ping requests:

```
https://www.google.com/ping?sitemap=https://example.com/sitemap.xml
```

Google deprecated this method in 2023, recommending Search Console or robots.txt instead [^google-build-sitemap].

## Sitemap Extensions

Google supports namespace extensions for specialized content [^google-sitemap-extensions]:

### Image Sitemap

```xml
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"
        xmlns:image="http://www.google.com/schemas/sitemap-image/1.1">
  <url>
    <loc>https://example.com/page</loc>
    <image:image>
      <image:loc>https://example.com/image.jpg</image:loc>
    </image:image>
  </url>
</urlset>
```

### Video Sitemap

```xml
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"
        xmlns:video="http://www.google.com/schemas/sitemap-video/1.1">
  <url>
    <loc>https://example.com/video-page</loc>
    <video:video>
      <video:thumbnail_loc>https://example.com/thumb.jpg</video:thumbnail_loc>
      <video:title>Video Title</video:title>
      <video:description>Description</video:description>
    </video:video>
  </url>
</urlset>
```

### Hreflang (Internationalization)

For multilingual sites, use the xhtml namespace [^hreflang-sitemap]:

```xml
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"
        xmlns:xhtml="http://www.w3.org/1999/xhtml">
  <url>
    <loc>https://example.com/en/page</loc>
    <xhtml:link rel="alternate" hreflang="en" href="https://example.com/en/page"/>
    <xhtml:link rel="alternate" hreflang="es" href="https://example.com/es/page"/>
    <xhtml:link rel="alternate" hreflang="x-default" href="https://example.com/en/page"/>
  </url>
</urlset>
```

**Key rules:**
- Each URL entry must include self-referencing hreflang
- Bidirectional linking required (A links to B, B links to A)
- Use `x-default` for language fallback

### News Sitemap

```xml
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"
        xmlns:news="http://www.google.com/schemas/sitemap-news/0.9">
  <url>
    <loc>https://example.com/news/article</loc>
    <news:news>
      <news:publication>
        <news:name>Example News</news:name>
        <news:language>en</news:language>
      </news:publication>
      <news:publication_date>2026-02-04</news:publication_date>
      <news:title>Article Title</news:title>
    </news:news>
  </url>
</urlset>
```

## Best Practices

### URLs to Include

- Canonical URLs only (not duplicates or alternate versions)
- Pages you want indexed
- Pages that return 200 status codes

### URLs to Exclude

- Non-canonical URLs (use canonical version instead)
- URLs blocked by robots.txt
- URLs with `noindex` meta tag
- Redirect URLs (3xx)
- Error pages (4xx, 5xx)
- Low-quality pages (thin content, tag archives)
- URLs with sensitive parameters

### lastmod Accuracy

Google only uses `<lastmod>` if it's verifiably accurate [^google-build-sitemap]. Best practices:

- Update only when content meaningfully changes (not for minor edits)
- Don't use future dates
- Don't update for copyright year changes
- Consider automating based on actual content changes

### Common Mistakes

| Mistake | Impact |
|---------|--------|
| Including noindex pages | Wastes crawl budget, confuses signals |
| Stale lastmod dates | Google may ignore the field entirely |
| All priorities set to 1.0 | Defeats the purpose (and Google ignores it anyway) |
| Relative URLs | Validation error |
| Wrong encoding | Parsing failure |
| Exceeding size limits | Partial crawling |

## AI Crawler Behavior

AI crawlers like GPTBot and ClaudeBot vary in how they use sitemaps [^cloudflare-crawlers]:

- **GPTBot** (OpenAI): Inconsistent sitemap usage; sometimes fetches once, sometimes skips entirely
- **ClaudeBot** (Anthropic): More consistent sitemap fetching behavior observed
- **Major AI crawlers** generally discover sites through link-following and may reference sitemaps

Unlike traditional search engine crawlers, AI training crawlers don't have mature sitemap-based discovery systems yet. They primarily use:
- Link-following from indexed sites
- Public website lists
- robots.txt for permission checking

## Validation

### Schema Validation

The official XSD schemas are available at sitemaps.org:
- Sitemap: `http://www.sitemaps.org/schemas/sitemap/0.9/sitemap.xsd`
- Sitemap Index: `http://www.sitemaps.org/schemas/sitemap/0.9/siteindex.xsd`

Validation can be performed with `xmllint` [^xmllint-validation]:

```bash
xmllint --schema sitemap.xsd sitemap.xml --noout
```

### Common Validation Errors

| Error | Cause |
|-------|-------|
| Namespace mismatch | Missing or incorrect xmlns declaration |
| Invalid child element | Elements in wrong order per XSD |
| Unescaped characters | Missing entity encoding for &, <, etc. |
| Invalid URL format | Relative URLs or malformed URIs |
| Encoding error | Non-UTF-8 encoding |

### Google Search Console

Search Console provides the most authoritative validation:
- Detects URLs returning errors
- Identifies pages blocked by robots.txt
- Reports indexing status per URL
- Shows crawl errors specific to your site

## Tools and Libraries

### Node.js / TypeScript

**sitemap.js** - Actively maintained, TypeScript-native [^sitemap-js]:

```typescript
import { SitemapStream, streamToPromise } from 'sitemap'

const stream = new SitemapStream({ hostname: 'https://example.com' })
stream.write({ url: '/page', lastmod: '2026-02-04' })
stream.end()

const sitemap = await streamToPromise(stream)
```

Features:
- Streaming for large sitemaps
- Automatic sitemap index generation (`SitemapAndIndexStream`)
- CLI for validation: `npx sitemap --validate sitemap.xml`
- All extensions supported (image, video, news, hreflang)

### Online Validators

- [XML Sitemap Validator](https://www.xml-sitemaps.com/validate-xml-sitemap.html) - Basic XSD validation
- [Google Search Console](https://search.google.com/search-console) - Authoritative validation with indexing data

## Potential semantic-kit Functionality

Based on this research, semantic-kit could offer the following sitemap-related features:

### `sitemap` Command - View/Inspect Sitemaps

Display sitemap contents with parsed metadata:

```
bun run semantic-kit:dev sitemap https://example.com/sitemap.xml
```

**Output could include:**
- URL count and file size
- lastmod distribution (oldest, newest, range)
- Extension usage (images, video, news, hreflang)
- For sitemap indexes: list of child sitemaps with their metadata

**Flags:**
- `--discover` - Find sitemaps via robots.txt, common paths, and HTML links
- `--expand` - For index files, fetch and summarize all child sitemaps
- `--urls` - Output just the URL list (useful for piping)

### `validate:sitemap` Command - Validate Sitemaps

Validate sitemap structure and contents:

```
bun run semantic-kit:dev validate:sitemap https://example.com/sitemap.xml
```

**Validation checks:**
- XSD schema compliance (using official sitemaps.org schemas)
- UTF-8 encoding verification
- URL format validation (absolute URLs, proper escaping)
- Extension namespace declarations
- Size limit warnings (approaching 50,000 URLs or 50MB)

**Optional deep validation (with flag):**
- Check URL status codes (identify 404s, redirects)
- Cross-reference with robots.txt (identify blocked URLs)
- Verify lastmod accuracy (compare with actual page headers)

### Discovery Feature

Automatic sitemap discovery for a domain:

```
bun run semantic-kit:dev sitemap --discover https://example.com
```

**Discovery methods (in order):**
1. Parse robots.txt for `Sitemap:` directives
2. Check common paths: `/sitemap.xml`, `/sitemap_index.xml`, `/sitemap-index.xml`
3. Check HTML `<link rel="sitemap">` on homepage

### Implementation Notes

**Recommended library:** `sitemap` (ekalinin/sitemap.js)
- TypeScript-native, actively maintained
- Has parsing and validation capabilities built-in
- Streaming support for large sitemaps
- CLI could be wrapped or used as reference

**Considerations:**
- Large sitemaps need streaming to avoid memory issues
- Deep URL validation should be opt-in (can be slow/rate-limited)
- Consider caching parsed sitemaps for repeated operations

## Related Pages

- [[web-crawlers]] - How search engines and AI crawlers discover content
- [[googlebot]] - Google's crawling behavior
- [[ai-crawler-behavior]] - AI crawler JavaScript and content extraction

## References

[^sitemaps-org]:
  - **Source**: sitemaps.org
  - **Title**: "Sitemaps XML format"
  - **URL**: https://www.sitemaps.org/protocol.html
  - **Accessed**: 2026-02-04
  - **Supports**: Protocol specification, element definitions, encoding requirements

[^sitemaps-protocol]:
  - **Source**: sitemaps.org
  - **Title**: "Sitemaps XML format - Protocol"
  - **URL**: https://www.sitemaps.org/protocol.html
  - **Accessed**: 2026-02-04
  - **Supports**: Required elements, character escaping, size limits

[^google-build-sitemap]:
  - **Source**: Google Search Central
  - **Title**: "Build and Submit a Sitemap"
  - **URL**: https://developers.google.com/search/docs/crawling-indexing/sitemaps/build-sitemap
  - **Accessed**: 2026-02-04
  - **Supports**: Google's lastmod handling, ignored elements, submission methods

[^google-large-sitemaps]:
  - **Source**: Google Search Central
  - **Title**: "Manage Your Sitemaps With Sitemap Index Files"
  - **URL**: https://developers.google.com/search/docs/crawling-indexing/sitemaps/large-sitemaps
  - **Accessed**: 2026-02-04
  - **Supports**: Sitemap index format, directory rules

[^google-sitemap-extensions]:
  - **Source**: Google Search Central
  - **Title**: "How to Combine Sitemap Extensions"
  - **URL**: https://developers.google.com/search/docs/crawling-indexing/sitemaps/combine-sitemap-extensions
  - **Accessed**: 2026-02-04
  - **Supports**: Image, video, news, hreflang namespace declarations

[^robots-txt-sitemap]:
  - **Source**: Ayima
  - **Title**: "A guide to adding a sitemap to your Robots.txt file"
  - **URL**: https://www.ayima.com/insights/robots-txt-sitemap.html
  - **Accessed**: 2026-02-04
  - **Supports**: Sitemap autodiscovery via robots.txt

[^astro-sitemap]:
  - **Source**: Astro Documentation
  - **Title**: "@astrojs/sitemap"
  - **URL**: https://docs.astro.build/en/guides/integrations-guide/sitemap/
  - **Accessed**: 2026-02-04
  - **Supports**: HTML link rel="sitemap" discovery method

[^hreflang-sitemap]:
  - **Source**: Search Engine Land
  - **Title**: "How To Implement The hreflang Element Using XML Sitemaps"
  - **URL**: https://searchengineland.com/how-to-implement-the-hreflang-element-using-xml-sitemaps-123030
  - **Accessed**: 2026-02-04
  - **Supports**: Hreflang implementation in sitemaps, bidirectional linking rules

[^cloudflare-crawlers]:
  - **Source**: Cloudflare Blog
  - **Title**: "From Googlebot to GPTBot: who's crawling your site in 2025"
  - **URL**: https://blog.cloudflare.com/from-googlebot-to-gptbot-whos-crawling-your-site-in-2025/
  - **Accessed**: 2026-02-04
  - **Supports**: AI crawler sitemap behavior observations

[^xmllint-validation]:
  - **Source**: Tobias Schwarz
  - **Title**: "Script to validate XML sitemaps against the XML schema"
  - **URL**: https://www.tobias-schwarz.com/blog/13/
  - **Accessed**: 2026-02-04
  - **Supports**: XSD validation with xmllint

[^sitemap-js]:
  - **Source**: GitHub
  - **Title**: "ekalinin/sitemap.js"
  - **URL**: https://github.com/ekalinin/sitemap.js
  - **Accessed**: 2026-02-04
  - **Supports**: Node.js/TypeScript library features, CLI capabilities, streaming support
